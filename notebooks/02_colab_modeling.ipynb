{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Colab Modeling Notebook\n",
        "\n",
        "Ce notebook permet d\u0019installer les d\u001apendances, v\u001aerifier les donn\u001ees, faire une CV rapide et g\u001anerer une soumission avec LightGBM (et CatBoost optionnel).\n",
        "\n",
        "Pr\u001arequis c\u001at\u001a: le r\u001aepo est clon\u001a\u001a dans Colab et le dossier `data/` contient:\n",
        "- `data/train.csv`, `data/test.csv`\n",
        "- `data/external/traffic/traffic_hourly_agg.parquet`\n",
        "- `data/external/weather/meteostat_hourly_from_daily.parquet`\n",
        "- `data/external/calendar/zone_c_holidays.csv`\n",
        "- `data/external/france_lockdowns.csv`\n",
        "- (optionnel) `data/external/events/events.csv`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install minimal deps (Colab)\n",
        "import sys, subprocess\n",
        "pkgs = [\"pandas\",\"numpy\",\"scikit-learn\",\"lightgbm\",\"catboost\",\"pyarrow\",\"workalendar\"]\n",
        "for p in pkgs:\n",
        "    try:\n",
        "        __import__(p.split(\"==\")[0])\n",
        "    except Exception:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", p])\n",
        "print(\"Ready.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data paths\n",
        "from pathlib import Path\n",
        "import os\n",
        "base = Path('.')\n",
        "paths = [\n",
        "    base/'data/train.csv',\n",
        "    base/'data/test.csv',\n",
        "    base/'data/external/traffic/traffic_hourly_agg.parquet',\n",
        "    base/'data/external/weather/meteostat_hourly_from_daily.parquet',\n",
        "    base/'data/external/calendar/zone_c_holidays.csv',\n",
        "]\n",
        "for p in paths:\n",
        "    print(p, 'OK' if p.exists() else 'MISSING')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick EDA\n",
        "import pandas as pd\n",
        "train = pd.read_csv('data/train.csv', parse_dates=['id'])\n",
        "print(train.describe())\n",
        "print(train.isna().mean())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CV and train utilities\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from feature_engineering import build_features, TARGET_COLUMNS\n",
        "from winsorize_targets import winsorize\n",
        "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load\n",
        "train_df = pd.read_csv('data/train.csv', parse_dates=['id'])\n",
        "train_df = winsorize(train_df)\n",
        "test_df = pd.read_csv('data/test.csv', parse_dates=['id'])\n",
        "train_df['is_train'] = 1\n",
        "test_df['is_train'] = 0\n",
        "test_df = test_df.assign(**{c: np.nan for c in TARGET_COLUMNS})\n",
        "full = pd.concat([train_df, test_df], ignore_index=True)\n",
        "full_feat = build_features(full)\n",
        "feat_cols = [c for c in full_feat.columns if c not in ('id','is_train') and c not in TARGET_COLUMNS]\n",
        "train_feat = full_feat[full_feat['is_train']==1].reset_index(drop=True)\n",
        "test_feat = full_feat[full_feat['is_train']==0].reset_index(drop=True)\n",
        "print('Features:', len(feat_cols))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2-fold CV then fit full and write submission\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "preds = {\"id\": test_feat[\"id\"].dt.strftime(\"%Y-%m-%d %H\")}\n",
        "for target in TARGET_COLUMNS:\n",
        "    y = train_feat[target].values\n",
        "    X = train_feat[feat_cols]\n",
        "    valid_mask = ~np.isnan(y)\n",
        "    for c in feat_cols:\n",
        "        valid_mask &= ~X[c].isna().values\n",
        "    Xv, yv = X[valid_mask], y[valid_mask]\n",
        "\n",
        "    model = LGBMRegressor(n_estimators=2000, learning_rate=0.03, num_leaves=63,\n",
        "                          subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1,\n",
        "                          reg_lambda=0.1, random_state=42, n_jobs=-1)\n",
        "    # simple split\n",
        "    n = len(Xv); val = min(24*7, max(24*7, n//10))\n",
        "    tr = n - val\n",
        "    X_tr, y_tr = Xv.iloc[:tr], yv[:tr]\n",
        "    X_va, y_va = Xv.iloc[tr:], yv[tr:]\n",
        "    model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], eval_metric='l1', callbacks=[early_stopping(50), log_evaluation(0)])\n",
        "    preds[target] = model.predict(test_feat[feat_cols])\n",
        "\n",
        "sub = pd.DataFrame(preds)\n",
        "sub = sub[[\"id\"] + TARGET_COLUMNS]\n",
        "sub.to_csv('submissions/submission_colab_lgbm.csv', index=False)\n",
        "print('Wrote submissions/submission_colab_lgbm.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CatBoost training and submission\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "\n",
        "preds_cb = {\"id\": test_feat[\"id\"].dt.strftime(\"%Y-%m-%d %H\")}\n",
        "for target in TARGET_COLUMNS:\n",
        "    y = train_feat[target].values\n",
        "    X = train_feat[feat_cols]\n",
        "    valid_mask = ~np.isnan(y)\n",
        "    for c in feat_cols:\n",
        "        valid_mask &= ~X[c].isna().values\n",
        "    Xv, yv = X[valid_mask], y[valid_mask]\n",
        "\n",
        "    model = CatBoostRegressor(\n",
        "        iterations=2000, learning_rate=0.03, depth=8, l2_leaf_reg=3.0,\n",
        "        loss_function=\"MAE\", eval_metric=\"MAE\", random_seed=42,\n",
        "        verbose=False, allow_writing_files=False\n",
        "    )\n",
        "    # simple split\n",
        "    n = len(Xv)\n",
        "    val = min(24*7, max(24*7, n//10))\n",
        "    tr = n - val\n",
        "    X_tr, y_tr = Xv.iloc[:tr], yv[:tr]\n",
        "    X_va, y_va = Xv.iloc[tr:], yv[tr:]\n",
        "    model.fit(Pool(X_tr, y_tr), eval_set=Pool(X_va, y_va), use_best_model=True)\n",
        "    preds_cb[target] = model.predict(test_feat[feat_cols])\n",
        "\n",
        "sub_cb = pd.DataFrame(preds_cb)\n",
        "sub_cb = sub_cb[[\"id\"] + TARGET_COLUMNS]\n",
        "sub_cb.to_csv(\"submissions/submission_colab_catboost.csv\", index=False)\n",
        "print(\"Wrote submissions/submission_colab_catboost.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
